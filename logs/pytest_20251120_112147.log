============================= test session starts ==============================
platform linux -- Python 3.13.9, pytest-9.0.1, pluggy-1.6.0
rootdir: /home/harish/harry_ws/hd_map_builder
configfile: pyproject.toml
collected 23 items

tests/test_bag_reader.py .                                               [  4%]
tests/test_calibration.py ..                                             [ 13%]
tests/test_export_map.py ..                                              [ 21%]
tests/test_export_profile.py ..                                          [ 30%]
tests/test_localization_stream.py .                                      [ 34%]
tests/test_multi_sensor_fusion.py .                                      [ 39%]
tests/test_neural_repr.py ..                                             [ 47%]
tests/test_occupancy_grid.py ...                                         [ 60%]
tests/test_offline_builder.py .                                          [ 65%]
tests/test_onnx_runtime.py F                                             [ 69%]
tests/test_pipeline_cli.py .                                             [ 73%]
tests/test_pose_graph.py ..                                              [ 82%]
tests/test_ros_localization_node.py ..                                   [ 91%]
tests/test_simulation_cli.py .                                           [ 95%]
tests/test_training.py .                                                 [100%]

=================================== FAILURES ===================================
___________________________ test_run_onnx_benchmark ____________________________

tmp_path = PosixPath('/tmp/pytest-of-harish/pytest-25/test_run_onnx_benchmark0')

    def test_run_onnx_benchmark(tmp_path):
        model_path = tmp_path / "identity.onnx"
        _create_identity_model(model_path)
>       metrics = run_onnx_benchmark(model_path, batch_size=16, coord_dim=3, steps=3)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/test_onnx_runtime.py:23: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
hd_map_builder/neural_repr/onnx_runtime.py:29: in run_onnx_benchmark
    session = ort.InferenceSession(str(model_path), providers=["CPUExecutionProvider"])
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:485: in __init__
    self._create_inference_session(providers, provider_options, disabled_optimizers)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <onnxruntime.capi.onnxruntime_inference_collection.InferenceSession object at 0x71ce431c5160>
providers = ['CPUExecutionProvider'], provider_options = [{}]
disabled_optimizers = None

    def _create_inference_session(self, providers, provider_options, disabled_optimizers=None):
        available_providers = C.get_available_providers()
    
        # Tensorrt can fall back to CUDA if it's explicitly assigned. All others fall back to CPU.
        if "TensorrtExecutionProvider" in available_providers:
            if (
                providers
                and any(
                    provider == "CUDAExecutionProvider"
                    or (isinstance(provider, tuple) and provider[0] == "CUDAExecutionProvider")
                    for provider in providers
                )
                and any(
                    provider == "TensorrtExecutionProvider"
                    or (isinstance(provider, tuple) and provider[0] == "TensorrtExecutionProvider")
                    for provider in providers
                )
            ):
                self._fallback_providers = ["CUDAExecutionProvider", "CPUExecutionProvider"]
            else:
                self._fallback_providers = ["CPUExecutionProvider"]
        if "NvTensorRTRTXExecutionProvider" in available_providers:
            if (
                providers
                and any(
                    provider == "CUDAExecutionProvider"
                    or (isinstance(provider, tuple) and provider[0] == "CUDAExecutionProvider")
                    for provider in providers
                )
                and any(
                    provider == "NvTensorRTRTXExecutionProvider"
                    or (isinstance(provider, tuple) and provider[0] == "NvExecutionProvider")
                    for provider in providers
                )
            ):
                self._fallback_providers = ["CUDAExecutionProvider", "CPUExecutionProvider"]
            else:
                self._fallback_providers = ["CPUExecutionProvider"]
        # MIGraphX can fall back to ROCM if it's explicitly assigned. All others fall back to CPU.
        elif "MIGraphXExecutionProvider" in available_providers:
            if providers and any(
                provider == "ROCMExecutionProvider"
                or (isinstance(provider, tuple) and provider[0] == "ROCMExecutionProvider")
                for provider in providers
            ):
                self._fallback_providers = ["ROCMExecutionProvider", "CPUExecutionProvider"]
            else:
                self._fallback_providers = ["CPUExecutionProvider"]
        else:
            self._fallback_providers = ["CPUExecutionProvider"]
    
        # validate providers and provider_options before other initialization
        providers, provider_options = check_and_normalize_provider_args(
            providers, provider_options, available_providers
        )
    
        # Print a warning if user passed providers to InferenceSession() but the SessionOptions instance
        # already has provider information (e.g., via add_provider_for_devices()). The providers specified
        # here will take precedence.
        if self._sess_options is not None and (providers or provider_options) and self._sess_options.has_providers():
            warnings.warn(
                "Specified 'providers'/'provider_options' when creating InferenceSession but SessionOptions has "
                "already been configured with providers. InferenceSession will only use the providers "
                "passed to InferenceSession()."
            )
    
        session_options = self._sess_options if self._sess_options else C.get_default_session_options()
    
        self._register_ep_custom_ops(session_options, providers, provider_options, available_providers)
    
        if self._model_path:
>           sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E           onnxruntime.capi.onnxruntime_pybind11_state.Fail: [ONNXRuntimeError] : 1 : FAIL : Load model from /tmp/pytest-of-harish/pytest-25/test_run_onnx_benchmark0/identity.onnx failed:/onnxruntime_src/onnxruntime/core/graph/model.cc:181 onnxruntime::Model::Model(onnx::ModelProto&&, const onnxruntime::PathString&, const onnxruntime::IOnnxRuntimeOpSchemaRegistryList*, const onnxruntime::logging::Logger&, const onnxruntime::ModelOptions&) Unsupported model IR version: 12, max supported IR version: 11

.venv/lib/python3.13/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:573: Fail
=============================== warnings summary ===============================
tests/test_export_profile.py: 2627 warnings
  /home/harish/harry_ws/hd_map_builder/.venv/lib/python3.13/site-packages/onnxscript/converter.py:464: DeprecationWarning: Expression.__init__ got an unexpected keyword argument 'lineno'. Support for arbitrary keyword arguments is deprecated and will be removed in Python 3.15.
    expr = ast.Expression(expr, lineno=expr.lineno, col_offset=expr.col_offset)

tests/test_export_profile.py: 2627 warnings
  /home/harish/harry_ws/hd_map_builder/.venv/lib/python3.13/site-packages/onnxscript/converter.py:464: DeprecationWarning: Expression.__init__ got an unexpected keyword argument 'col_offset'. Support for arbitrary keyword arguments is deprecated and will be removed in Python 3.15.
    expr = ast.Expression(expr, lineno=expr.lineno, col_offset=expr.col_offset)

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ============================
FAILED tests/test_onnx_runtime.py::test_run_onnx_benchmark - onnxruntime.capi...
================= 1 failed, 22 passed, 5254 warnings in 9.49s ==================
